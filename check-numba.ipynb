{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.10.4\n"
     ]
    }
   ],
   "source": [
    "!python --version\n",
    "\n",
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'code.graph'; 'code' is not a package",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mcode\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgraph\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayered_walk\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m load_data\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'code.graph'; 'code' is not a package"
     ]
    }
   ],
   "source": [
    "from code.graph.layered_walk.utils import load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle \n",
    "import numpy as np \n",
    "import timeit \n",
    "import numba "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = \"/home/flavio/datasets/synthetic_layered_graph_1mil/\"\n",
    "layers = []\n",
    "# nsample = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(root + \"fake_\" + \"education\" + \"_adjacency_dict.pkl\", \"rb\") as pkl_file:\n",
    "#     edges = dict(pickle.load(pkl_file))\n",
    "#     users = list(edges.keys())\n",
    "#     users = users[:nsample]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_types = [\"family\", \"colleague\", \"education\", \"neighbor\", \"household\"]\n",
    "layer_types = [\"neighbor\", \"colleague\"]\n",
    "for ltype in layer_types:\n",
    "    with open(root + \"fake_\" + ltype + \"_adjacency_dict.pkl\", \"rb\") as pkl_file:\n",
    "        edges = dict(pickle.load(pkl_file))\n",
    "        # edges_keep = dict((u, edges[u]) for u in users)\n",
    "        layers.append(edges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users = list(layers[0].keys())\n",
    "len(users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(layers[0].keys())[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2, 3]\n",
      "[0, 1, 2, 3]\n"
     ]
    }
   ],
   "source": [
    "# print(users[:4])\n",
    "# for user in users: # XXX does this do anything? FIXME\n",
    "#     user += 5\n",
    "# print(users[:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5, 6, 7, 8, 9]\n"
     ]
    }
   ],
   "source": [
    "# users = [u + 5 for u in users]\n",
    "# print(users[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_layer_dict = {}\n",
    "for user in users:\n",
    "    node_layer_dict[user] = []\n",
    "    \n",
    "    for i, layer in enumerate(layers):\n",
    "        if user in layer:\n",
    "            if len(layer[user]) > 0:\n",
    "                node_layer_dict[user].append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "[0, 1]\n"
     ]
    }
   ],
   "source": [
    "a = list(node_layer_dict.keys())\n",
    "print(a[0])\n",
    "print(node_layer_dict[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 2]\n",
      "[216591, 359203, 303294, 629913, 941856, 657939, 33155, 184951, 293721, 665878, 214931, 483588, 505018, 838030, 139399, 228960, 629783, 589567, 700786, 428120, 736350, 929797, 462671, 654239, 822538, 973284]\n"
     ]
    }
   ],
   "source": [
    "print(list(layers[0].keys())[:3])\n",
    "print(layers[0][3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numba does not work with dicts. Can we replace the following dicts?\n",
    "- `layers`: a dict (layer type) of dicts (user id) of adjacency lists.\n",
    "- node_layer_dict: a dict (user id) of layer ids, indicating whether the user has connections in this layer\n",
    "\n",
    "\n",
    "could we not rewrite this as lists?\n",
    "- `layers`: one layer is a list of adjacency lists, where the first adjacency list is from the first user\n",
    "    - the user id refers to the order in the list\n",
    "    - `layers` is a list of lists of lists \n",
    "- `node_layer_dict`: similar to a single layer: the first list indicates which layers are present for the first user\n",
    "\n",
    "Chatgpt suggests to use numpy arrays for performance. Think; check this response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @numba.jit\n",
    "def custom_sample(choice_set: list):\n",
    "    \"custom function to apply np.random.choice\"\n",
    "    if len(choice_set) == 0:\n",
    "        return None \n",
    "    elif len(choice_set) == 1:\n",
    "        chosen = choice_set[0]\n",
    "    else:\n",
    "        chosen = np.random.choice(choice_set)\n",
    "    \n",
    "    return chosen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @numba.jit\n",
    "def generate_walks(unique_users: list, walk_len: int, p: float = 0.8):\n",
    "    \"Generate one random walk for each user\"\n",
    "    num_users = len(unique_users)\n",
    "    random_nums = np.random.rand(num_users, walk_len)\n",
    "\n",
    "    rows = []\n",
    "    for user_idx, user in enumerate(unique_users):   \n",
    "        current_node = user\n",
    "        \n",
    "        layer_indices = node_layer_dict[current_node]\n",
    "        layer_index = custom_sample(layer_indices)\n",
    "        if not layer_index:\n",
    "            break\n",
    "\n",
    "        current_layer = layers[layer_index]\n",
    "             \n",
    "        walk = [user]\n",
    "        while len(walk) < walk_len:\n",
    "            layer_indices = node_layer_dict[current_node]\n",
    "        \n",
    "            roll = random_nums[user_idx][len(walk)]\n",
    "            \n",
    "            if roll > p:\n",
    "                layer_index = custom_sample(layer_indices)\n",
    "                if not layer:\n",
    "                    break\n",
    "                \n",
    "            adjacent_nodes = current_layer[current_node]\n",
    "\n",
    "            # Layer index should encode the layer type in an integer 0-4\n",
    "            walk.append(layer_index)\n",
    "            \n",
    "            next_node = custom_sample(adjacent_nodes)\n",
    "            if not next_node:\n",
    "                break\n",
    "            \n",
    "            walk.append(next_node)\n",
    "            current_node = next_node\n",
    "        #assert len(walk) == walk_len, print(len(walk))\n",
    "        rows.append(walk)\n",
    "\n",
    "    return rows\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "walk_len = 40\n",
    "num_walks = 5\n",
    "a = generate_walks(unique_users=users, walk_len=walk_len)\n",
    "# call this function num_walks times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768 ms ± 97.6 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit generate_walks(unique_users=users, walk_len=walk_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_many_walks(users: list, walk_len: int, num_walks: int):\n",
    "    out = []\n",
    "    for _ in range(num_walks):\n",
    "        walks = generate_walks(unique_users=users, walk_len=walk_len)\n",
    "        out.append(walks)\n",
    "    return out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "799 ms ± 4.51 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit create_many_walks(users=users, walk_len=walk_len, num_walks=num_walks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try with typed dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "@numba.njit\n",
    "def custom_sample(choice_set: list):\n",
    "    \"custom function to apply np.random.choice\"\n",
    "    if len(choice_set) == 0:\n",
    "        return -1 \n",
    "    elif len(choice_set) == 1:\n",
    "        chosen = choice_set[0]\n",
    "    else:\n",
    "        chosen = np.random.choice(choice_set)\n",
    "    \n",
    "    return np.int32(chosen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cast layers, a list of dicts, into a list of numba typed dicts\n",
    "# cast node_layer_dict, a dict, into a numba typed dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba.typed import Dict, List\n",
    "from numba.core import types\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "node_layer_dict_numba = Dict.empty(\n",
    "    key_type=types.int32,\n",
    "    value_type=types.int32[:]\n",
    ")   \n",
    "i = 0\n",
    "for k, v in node_layer_dict.items():\n",
    "    # if i > 10:\n",
    "    #     break \n",
    "    k = types.int32(k)\n",
    "    node_layer_dict_numba[k] = np.asarray(v, dtype=np.int32)\n",
    "    i += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "layers_numba = []\n",
    "for layer in layers: \n",
    "    layer_numba = Dict.empty(\n",
    "        key_type=types.int32,\n",
    "        value_type=types.int32[:]\n",
    "    )\n",
    "    i = 0\n",
    "    for k, v in layer.items():\n",
    "        # if i > 10:\n",
    "        #     break \n",
    "        k = types.int32(k)\n",
    "        layer_numba[k] = np.asarray(v, dtype=np.int32)\n",
    "        i += 1\n",
    "        layers_numba.append(layer_numba)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "@numba.njit\n",
    "def single_walk(start_node: types.int32,\n",
    "                walk_len: int, \n",
    "                node_layer_dict: numba.typed.Dict, \n",
    "                layers: list,\n",
    "                p: float=0.8):\n",
    "    \"\"\"Create a single random walk starting at one node.\n",
    "    \n",
    "    Args:\n",
    "        start_node: the node from which to start\n",
    "        walk_len: the length of the random walk \n",
    "        node_layer_dict: dictionary indicating the layer indices in which each node as at least one edge.\n",
    "        layers: list of numba.typed.Dict. Each layer is an edge list, indicating the connected nodes for each node. \n",
    "        p: probability of resampling the layer. \n",
    "    \n",
    "    Returns:\n",
    "        np.array: a sequence of node identifiers\n",
    "    \"\"\"\n",
    "    current_node = start_node\n",
    "    # walk = List.empty_list(types.int32)\n",
    "    # walk.append(start_node)\n",
    "    walk = [start_node]\n",
    "\n",
    "    layer_indices = node_layer_dict[current_node]\n",
    "    layer_index = custom_sample(layer_indices)\n",
    "    if layer_index == -1:\n",
    "        return walk\n",
    "\n",
    "    # walk.append(start_node)\n",
    "    for draw in np.random.rand(walk_len, 1):\n",
    "    # while len(walk) < walk_len:\n",
    "        draw = draw[0]\n",
    "        layer_indices = node_layer_dict[current_node]\n",
    "        # roll = random_nums.pop()\n",
    "\n",
    "        if draw > p:\n",
    "            layer_index = custom_sample(layer_indices)\n",
    "            if layer_index == -1:\n",
    "                break\n",
    "\n",
    "        current_layer = layers[layer_index]\n",
    "        adjacent_nodes = current_layer[current_node]\n",
    "\n",
    "        walk.append(-layer_index - 1) # the first node is indicated by 0\n",
    "        next_node = custom_sample(adjacent_nodes)\n",
    "        if next_node == -1:\n",
    "            break\n",
    "        \n",
    "        walk.append(next_node)\n",
    "        current_node = next_node\n",
    "\n",
    "    return walk \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ListType[int32]([, ...])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# List.empty_list(types.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = single_walk(\n",
    "    start_node=10,\n",
    "    walk_len=5,\n",
    "    node_layer_dict=node_layer_dict_numba,\n",
    "    layers=layers_numba\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### ~~Now try with numpy arrays~~\n",
    "\n",
    "We first store the adjacency information in two separate arrays:\n",
    "- for each layer, a 1d array with the horizontally stacked adjacencies\n",
    "- for each layer, a 1d array with the the start index of i's neighbors in the adjacencies\n",
    "    - since arrays for each have the same shape (= number of nodes), we convert it into a 2d array of shape `[n_layers, n_users]`\n",
    "\n",
    "I will shift the node ids when generating the walks. This keeps the code for the arrays simpler."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "adjacencies = []\n",
    "adj_idx = []\n",
    "for current_layer in layers:\n",
    "    cur_adjacencies = []\n",
    "    # cur_adj_idx = [0] # let's implicitly assume the starting index for the first person is 0\n",
    "    cur_adj_idx = []\n",
    "    for i, (idx, neighbors) in enumerate(current_layer.items()):\n",
    "        assert i == idx\n",
    "        if len(cur_adj_idx) == 0:\n",
    "            new_idx = len(neighbors)\n",
    "        else:\n",
    "            new_idx = cur_adj_idx[-1] + len(neighbors)\n",
    "        cur_adj_idx.append(new_idx)\n",
    "        cur_adjacencies += neighbors\n",
    "\n",
    "    adj_idx.append(cur_adj_idx)\n",
    "    adjacencies.append(np.array(cur_adjacencies))\n",
    "\n",
    "\n",
    "adj_idx = np.array(adj_idx)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also need to store the `node_layer_dict` in a 2d array. The rows indicate users, the columns indicate they layer id. If `True`, user `i` has neighbors in layer `j`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes = list(layers[0].keys())\n",
    "n_layers = len(layers)\n",
    "nodes_and_layers = np.zeros((len(nodes), n_layers), dtype=np.bool_)\n",
    "# nodes_and_layers = np.zeros((len(nodes), n_layers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nodes_and_layers[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "for node in nodes:\n",
    "    node_layer = []\n",
    "    for i, adjacency in enumerate(adjacencies): \n",
    "        if adjacency[node] < adjacency[node+1]:\n",
    "            node_layer.append(i)\n",
    "    nodes_and_layers[node, node_layer] = 1\n",
    "   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can re-implement the generation of the walks using the three data structures\n",
    "- `nodes_and_layers`, a array indicating which user has neighbors in which layer\n",
    "- `adjacencies`, a list of arrays with adjacency information\n",
    "- `adj_idx`, an array of starting positions for user `i` in `adjacencies`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0]),)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node = 0\n",
    "a = np.where(nodes_and_layers[node, :])\n",
    "a\n",
    "# a = np.squeeze(a)\n",
    "# a.shape\n",
    "# a[0].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "@numba.jit\n",
    "def custom_sample(choice_set: list):\n",
    "    \"custom function to apply np.random.choice\"\n",
    "    # print(choice_set)\n",
    "    if len(choice_set) == 0:\n",
    "        return -1 \n",
    "    elif len(choice_set) == 1:\n",
    "        chosen = choice_set[0]\n",
    "    else:\n",
    "        chosen = np.random.choice(choice_set)\n",
    "    \n",
    "    return chosen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @numba.jit(nopython=True)\n",
    "def gen_walks_np(adjacencies: list, \n",
    "                 adj_idx: np.array, \n",
    "                 nodes_and_layers: np.array, \n",
    "                 walk_len: int, \n",
    "                 p: float=0.8):\n",
    "    n_nodes = nodes_and_layers.shape[0]\n",
    "    walks = np.zeros((n_nodes, walk_len), dtype=np.int32)\n",
    "    # walks = np.full((n_nodes, walk_len), -1, dtype=np.int32)\n",
    "    random_nums = np.random.rand(n_nodes, walk_len)\n",
    "    for node in range(n_nodes):\n",
    "        walk = np.full(walk_len, -1, dtype=np.int32)\n",
    "        available_layers = np.where(nodes_and_layers[node, :])[0]\n",
    "        # print(f\"available layers at start: {available_layers}\")\n",
    "        layer_index = custom_sample(available_layers)\n",
    "        if layer_index == -1:\n",
    "            walks[node, :] = walk\n",
    "            continue \n",
    "\n",
    "        current_layer = adjacencies[layer_index]\n",
    "        current_adj_idx = adj_idx[layer_index, :]\n",
    "    \n",
    "\n",
    "        current_node = node \n",
    "        # walk = walks[node, :]\n",
    "        walk[0] = node + 5\n",
    "\n",
    "        walk_pos = 1\n",
    "        while walk_pos < walk_len-1: # XXX b/c we add *two* items in each loop, we need to stop earlier\n",
    "            available_layers = np.where(nodes_and_layers[current_node, :])[0]\n",
    "            roll = random_nums[node, walk_pos - 1]\n",
    "            if roll > p:\n",
    "                layer_index = custom_sample(available_layers)\n",
    "                if layer_index == -1: \n",
    "                    break\n",
    "            \n",
    "            if node == 0:\n",
    "                end_idx = current_adj_idx[0]\n",
    "                adjacent_nodes = current_layer[:end_idx]\n",
    "            else:\n",
    "                start_idx = current_adj_idx[node -1]\n",
    "                end_idx = current_adj_idx[node]\n",
    "                adjacent_nodes = current_layer[start_idx:end_idx]\n",
    "\n",
    "\n",
    "            next_node = custom_sample(adjacent_nodes)\n",
    "\n",
    "            if next_node == -1:\n",
    "                break\n",
    "\n",
    "            walk[walk_pos] = layer_index\n",
    "            walk[walk_pos + 1] = next_node + 5\n",
    "            current_node = next_node\n",
    "            walk_pos += 2\n",
    "        \n",
    "        walks[node] = walk\n",
    "    return walks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "a = gen_walks_np(adjacencies=adjacencies,\n",
    "                 adj_idx=adj_idx,\n",
    "                 nodes_and_layers=nodes_and_layers,\n",
    "                 walk_len=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "walk_len = 40\n",
    "num_walks = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[38], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mget_ipython\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_line_magic\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtimeit\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgen_walks_np(adjacencies=adjacencies, adj_idx=adj_idx, nodes_and_layers=nodes_and_layers, walk_len=walk_len)\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/repositories/projects/odissei-life2vec/life-sequencing-dutch/.venv/lib/python3.10/site-packages/IPython/core/interactiveshell.py:2480\u001b[0m, in \u001b[0;36mInteractiveShell.run_line_magic\u001b[0;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[1;32m   2478\u001b[0m     kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocal_ns\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_local_scope(stack_depth)\n\u001b[1;32m   2479\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuiltin_trap:\n\u001b[0;32m-> 2480\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2482\u001b[0m \u001b[38;5;66;03m# The code below prevents the output from being displayed\u001b[39;00m\n\u001b[1;32m   2483\u001b[0m \u001b[38;5;66;03m# when using magics with decorator @output_can_be_silenced\u001b[39;00m\n\u001b[1;32m   2484\u001b[0m \u001b[38;5;66;03m# when the last Python token in the expression is a ';'.\u001b[39;00m\n\u001b[1;32m   2485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(fn, magic\u001b[38;5;241m.\u001b[39mMAGIC_OUTPUT_CAN_BE_SILENCED, \u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "File \u001b[0;32m~/repositories/projects/odissei-life2vec/life-sequencing-dutch/.venv/lib/python3.10/site-packages/IPython/core/magics/execution.py:1185\u001b[0m, in \u001b[0;36mExecutionMagics.timeit\u001b[0;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[1;32m   1183\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m10\u001b[39m):\n\u001b[1;32m   1184\u001b[0m     number \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m index\n\u001b[0;32m-> 1185\u001b[0m     time_number \u001b[38;5;241m=\u001b[39m \u001b[43mtimer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnumber\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1186\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m time_number \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.2\u001b[39m:\n\u001b[1;32m   1187\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/repositories/projects/odissei-life2vec/life-sequencing-dutch/.venv/lib/python3.10/site-packages/IPython/core/magics/execution.py:173\u001b[0m, in \u001b[0;36mTimer.timeit\u001b[0;34m(self, number)\u001b[0m\n\u001b[1;32m    171\u001b[0m gc\u001b[38;5;241m.\u001b[39mdisable()\n\u001b[1;32m    172\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 173\u001b[0m     timing \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minner\u001b[49m\u001b[43m(\u001b[49m\u001b[43mit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    174\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    175\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m gcold:\n",
      "File \u001b[0;32m<magic-timeit>:1\u001b[0m, in \u001b[0;36minner\u001b[0;34m(_it, _timer)\u001b[0m\n",
      "Cell \u001b[0;32mIn[35], line 46\u001b[0m, in \u001b[0;36mgen_walks_np\u001b[0;34m(adjacencies, adj_idx, nodes_and_layers, walk_len, p)\u001b[0m\n\u001b[1;32m     42\u001b[0m     end_idx \u001b[38;5;241m=\u001b[39m current_adj_idx[node]\n\u001b[1;32m     43\u001b[0m     adjacent_nodes \u001b[38;5;241m=\u001b[39m current_layer[start_idx:end_idx]\n\u001b[0;32m---> 46\u001b[0m next_node \u001b[38;5;241m=\u001b[39m \u001b[43mcustom_sample\u001b[49m\u001b[43m(\u001b[49m\u001b[43madjacent_nodes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m next_node \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%timeit gen_walks_np(adjacencies=adjacencies, adj_idx=adj_idx, nodes_and_layers=nodes_and_layers, walk_len=walk_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@numba.jit\n",
    "def test_numba(nodes_and_layers):\n",
    "    n_nodes = nodes_and_layers.shape[0]\n",
    "    for node in range(n_nodes):\n",
    "        available_layers = np.where(nodes_and_layers[node, :])[0]\n",
    "        layer_index = custom_sample(available_layers)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_numba(nodes_and_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# @numba.jit\n",
    "def generate_walks(unique_users: list, walk_len: int, p: float = 0.8):\n",
    "    \"Generate one random walk for each user\"\n",
    "    num_users = len(unique_users)\n",
    "    random_nums = np.random.rand(num_users, walk_len)\n",
    "\n",
    "    rows = []\n",
    "    for user_idx, user in enumerate(unique_users):   \n",
    "        current_node = user\n",
    "        \n",
    "        layer_indices = node_layer_dict[current_node]\n",
    "        layer_index = custom_sample(layer_indices)\n",
    "        if not layer_index:\n",
    "            break\n",
    "\n",
    "        current_layer = layers[layer_index]\n",
    "             \n",
    "        walk = [user]\n",
    "        while len(walk) < walk_len:\n",
    "            layer_indices = node_layer_dict[current_node]\n",
    "        \n",
    "            roll = random_nums[user_idx][len(walk)]\n",
    "            \n",
    "            if roll > p:\n",
    "                layer_index = custom_sample(layer_indices)\n",
    "                if not layer_index:\n",
    "                    break\n",
    "                \n",
    "            adjacent_nodes = current_layer[current_node]\n",
    "\n",
    "            # Layer index should encode the layer type in an integer 0-4\n",
    "            walk.append(layer_index)\n",
    "            \n",
    "            next_node = custom_sample(adjacent_nodes)\n",
    "            if not next_node:\n",
    "                break\n",
    "            \n",
    "            walk.append(next_node)\n",
    "            current_node = next_node\n",
    "        #assert len(walk) == walk_len, print(len(walk))\n",
    "        rows.append(walk)\n",
    "\n",
    "    return rows\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
