{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python 3.10.4\n"
     ]
    }
   ],
   "source": [
    "!python --version\n",
    "\n",
    "import os \n",
    "import timeit \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import load_data, convert_to_numba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "users, layers, node_layer_dict = load_data([\"neighbor\", \"colleague\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to use numba, we need to store the data in numba-compatible objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_numba, layers_numba, node_layer_dict_numba = convert_to_numba(users, layers, node_layer_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: This creates substantial overhead. Is it worth it when creating many, many walks? How does it scale with the size of the graph/the number of layers?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interestingly, numba objects are much smaller than python objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "88\n",
      "48\n",
      "41943136\n",
      "48\n",
      "8000056\n",
      "48\n"
     ]
    }
   ],
   "source": [
    "import sys \n",
    "print(sys.getsizeof(layers))\n",
    "print(sys.getsizeof(layers_numba))\n",
    "\n",
    "print(sys.getsizeof(node_layer_dict))\n",
    "print(sys.getsizeof(node_layer_dict_numba))\n",
    "\n",
    "print(sys.getsizeof(users))\n",
    "print(sys.getsizeof(users_numba))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare running time of single walk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.walks_numba import single_walk as single_walk_numba\n",
    "from src.walks import single_walk as single_walk_python\n",
    "walk_len = 5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit single_walk_python(10, walk_len, node_layer_dict, layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/flavio/repositories/projects/odissei-life2vec/layered_walk/src/walks_numba.py:65: NumbaTypeSafetyWarning: \u001b[1m\u001b[1m\u001b[1munsafe cast from int64 to int32. Precision may be lost.\u001b[0m\u001b[0m\u001b[0m\n",
      "  layer_indices = node_layer_dict[current_node]\n"
     ]
    }
   ],
   "source": [
    "# compile\n",
    "_ = single_walk_numba(10, walk_len, node_layer_dict_numba, layers_numba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.71 μs ± 397 ns per loop (mean ± std. dev. of 7 runs, 100,000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit single_walk_numba(10, 5, node_layer_dict_numba, layers_numba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compare running time for a set of nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.walks_numba import create_walks as create_walks_numba\n",
    "from src.walks import create_walks as create_walks_python\n",
    "\n",
    "sample_size = 200_000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17.7 s ± 1.53 s per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit create_walks_python(users[:sample_size], walk_len, node_layer_dict, layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile \n",
    "_ = create_walks_numba(users_numba[:sample_size], walk_len, node_layer_dict_numba, layers_numba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "956 ms ± 3.93 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit create_walks_numba(users_numba[:sample_size], walk_len, node_layer_dict_numba, layers_numba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parallelize the numba-compiled code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def walks_wrapper(users):\n",
    "    return create_walks_numba(users, 5, node_layer_dict_numba, layers_numba, 0.8)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = walks_wrapper(users[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import batched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://esciencecenter-digital-skills.github.io/parallel-python-workbench/extra-asyncio.html\n",
    "from dataclasses import dataclass\n",
    "from typing import Optional\n",
    "from time import perf_counter\n",
    "from contextlib import asynccontextmanager\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Elapsed:\n",
    "    time: Optional[float] = None\n",
    "\n",
    "\n",
    "@asynccontextmanager\n",
    "async def timer():\n",
    "    e = Elapsed()\n",
    "    t = perf_counter()\n",
    "    yield e\n",
    "    e.time = perf_counter() - t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def create_walks_parallel(users, n, n_workers):\n",
    "    result = await asyncio.gather(*(asyncio.to_thread(walks_wrapper, batch) for batch in batched(users[:n], n//n_workers)))\n",
    "    return result \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "that took 0.4622826839913614 seconds\n"
     ]
    }
   ],
   "source": [
    "async with timer() as t:  # does not seem to parallelize; speed is very volatile\n",
    "    result = await create_walks_parallel(users, sample_size, 8)\n",
    "\n",
    "print(f\"that took {t.time} seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we created 200000 walks of length 11\n"
     ]
    }
   ],
   "source": [
    "n_walks = sum(len(x) for x in result)\n",
    "final_length = len(result[0][0])\n",
    "assert final_length >= walk_len # we also store the identifiers of the layers, which adds elements to the walk\n",
    "\n",
    "print(f\"we created {n_walks} walks of length {final_length}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In sum: to process the first 200k nodes, we take \n",
    "- 17s with pure python\n",
    "- 1s with sequential numba\n",
    "- 500ms with parallel numba. \n",
    "    - this means almost 34x speedup compared to pure python\n",
    "    - but it is volatile: sometimes it takes 1.7s, thus longer than sequential numba!\n",
    "\n",
    "### Notes / next steps\n",
    "- there is a sweet spot in the optimal batch size for parallelization\n",
    "- the parallel processing should be able to pass in batches in sequence (ie, there may be more batches than processes, and we cannot process all batches at the same time)\n",
    "- try parallel processing also with `concurrent.features` (see below)\n",
    "- try also with concurrent.futures? multithreading module?\n",
    "- extend functionality of the walks function: do not store the layer types; run only on one layer (-> more classical deepwalk)\n",
    "- also check which other libraries are out there: is it worth making this reusable?\n",
    "    - networkx\n",
    "    - deepwalk implementations?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try with concurrent.futures\n",
    "\n",
    "this does not look like it's parallelized.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_walks_parallel_pool(n, n_workers):\n",
    "    with concurrent.futures.ThreadPoolExecutor(max_workers=n_workers) as executor:\n",
    "        future = (executor.submit(\n",
    "                walks_wrapper, batch\n",
    "            ) for batch in batched(users[:n], n//n_workers)\n",
    "        )\n",
    "        # results = executor.map(wrapped_walks_numba, users[:n], chunksize=1)\n",
    "        res = [f.result() for f in future]\n",
    "        return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = create_walks_parallel_pool(sample_size, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we created 200000 walks of length 11\n"
     ]
    }
   ],
   "source": [
    "n_walks = sum(len(x) for x in res)\n",
    "final_length = len(result[0][0])\n",
    "assert final_length >= walk_len # we also store the identifiers of the layers, which adds elements to the walk\n",
    "\n",
    "print(f\"we created {n_walks} walks of length {final_length}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.14 s ± 33.7 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit create_walks_parallel_pool(sample_size, 2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
